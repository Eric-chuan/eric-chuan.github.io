<!DOCTYPE html>
<!-- saved from url=(0030)https://denghilbert.github.io/ -->
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jingchuan Hu's Homepage</title>

    <meta name="author" content="Jingchuan Hu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Jingchuan Hu, SJTU">
    <link rel="stylesheet" type="text/css" href="./stylesheet.css">
    <link rel="icon" href="https://Eric-chuan.github.io/images/icon.png">
    <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-25H6S86264"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'G-25H6S86264');
    </script>
</head>

<!-- Google tag (gtag.js) -->



<body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding:0px">
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:collapse;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr style="padding:0px">
                                <td style="padding:2.5%;width:60%;vertical-align:middle">
                                    <p style="text-align:center">
                                        <name>Jingchuan Hu</name>
                                    </p>
                                    <p>
                                        Hi, I am Jingchuan Hu, you can call me Eric.
                                    </p>

                                    <p>
                                        I'm now working at Alibaba as an engineer. I obtained my Master's degree from SJTU, during which time I conducted research at the <a href="https://medialab.sjtu.edu.cn/">MediaLab</a> under the supvervision of <a href="https://medialab.sjtu.edu.cn/author/li-song/">Prof. Li Song</a>. Before that, I received My B.Sc.degree in the same university.
                                    </p>

                                    <p>
                                        My research interests include FreeView Video, Neural Rendering, Digital Human and 3D Vision. I am also exploring the power of AIGC and is an enthusiast of <a href="https://ommer-lab.com/research/latent-diffusion-models/">Stable Diffusion</a>.
                                        Please feel free to contact me by email!
                                    </p>

                                    <p style="text-align:center">
                                        <!-- <a href="./blogs.html">Blogs</a> &nbsp;/&nbsp; -->
                                        <a href="mailto:ericchuan1997@gmail.com">Email</a> &nbsp;/&nbsp;
                                        <a href="https://github.com/Eric-chuan">Github</a> &nbsp;/&nbsp;
                                        <a href="resume/CV_zh.pdf">CV</a> &nbsp;/&nbsp;
                                    </p>


                                </td>
                                <td style="padding:2.5%;width:30%;max-width:30%">
                                    <a href="https://Eric-chuan.github.io/images/me.png"><img style="width:100%;max-width:100%" alt="profile photo" src="./images/me.png" class="hoverZoomLink"></a>
                                    <p></p>
                                    <!-- <details close="">
                                        <summary>What's this?</summary>
                                        <p>This photo was generated with a <a href="https://ommer-lab.com/research/latent-diffusion-models/">Stable Diffusion</a> model, finetuned on a set of 11 headshots of me, using <a href="https://arxiv.org/abs/2208.12242">DreamBooth</a>.
                                            I can confirm it's rather accurate. Contact me for more fun prompts & results!</p>
                                    </details> -->
                                    <p></p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Research</heading>
                                    <p>
                                        My current research interests lie in the intersection of 3D vision and Graphics, specifically in FreeView Video, Neural Rendering, Digital Human and 3D Vision, etc.
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table style="width:100%;border:0;border-collapse:collapse;border-spacing:0;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/TaoAvatar-Teaser.png" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a>                                       </papertitle>
                                        <papertitle>TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting</papertitle>
                                    </a>
                                    <br>
                                    <a>Jianchuan Chen<sup>*</sup></a>,
                                    <u><strong>Jingchuan Hu<sup>*</sup></strong></u>,
                                    <a>GaiGe Wang</a>,
                                    <a>Zhonghua Jiang</a>,
                                    <a>Tiansong Zhou</a>,
                                    <a>Zhiwen Chen<sup>‡</sup></a>,
                                    <a>Chengfei Lv<sup>†</sup></a>

                                    <br>
                                    <em>CVPR 2025</em>
                                    <br>
                                    <p></p>
                                    <p>
                                        We introduce TaoAvatar, which generates photorealistic, topology-consistent 3D full-body avatars from multi-view sequences. It provides high-quality, real-time rendering with low storage requirements, compatible across various mobile and AR devices like the Apple Vision Pro.
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/TMM23-ShuaiGuo.png" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a> 
                                        <papertitle>Real-Time Free Viewpoint Video Synthesis System Based on DIBR and A Depth Estimation Network</papertitle>
                                    </a>
                                    <br>
                                    <a>Shuai Guo</a>,
                                    <u><strong>Jingchuan Hu</strong></u>,
                                    <a>Kai Zhou</a>,
                                    <a>Jionghao Wang</a>,
                                    <a href="https://medialab.sjtu.edu.cn/author/li-song/">Li Song</a>,
                                    <a>Rong Xie</a>,
                                    <a>WenJun Zhang</a>

                                    <br>
                                    <em>TMM 2023</em>
                                    <br>
                                    <p></p>
                                    <p>
                                        In this paper, we introduce a real-time FVV synthesis system based on DIBR and a depth estimation network. Specifically, our system includes a multi-view synchronous video capture system, a multi-stage depth estimation network, a GPU-accelerated DIBR algorithm, and a virtual view parameters generation method.
                                        We also introduce a high-quality multi-view RGB-D synchronous dataset for the training of our depth estimation network. As far as we know, our system provides the first complete real-time FVV solution at a fixed field based on DIBR and a depth estimation network.
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/ICME22-System.png" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a href="https://ieeexplore.ieee.org/document/9859922/"> 
                                        <papertitle>A Multi-user Oriented Live Free-viewpoint Video Streaming System Based On View Interpolation</papertitle>
                                    </a>
                                    <br>
                                    <u><strong>Jingchuan Hu</strong></u>,
                                    <a>Shuai Guo</a>,
                                    <a>Kai Zhou</a>,
                                    <a>Yu Dong</a>,
                                    <a>Jun Xu</a>,
                                    <a href="https://medialab.sjtu.edu.cn/author/li-song/">Li Song</a>

                                    <br>
                                    <em>ICME '22</em>
                                    <br>
                                    <p></p>
                                    <p>
                                        In this paper, we novelly introduce a CNN-based view interpolation algorithm to synthesis dense virtual views in real time. 
                                        Based on this, we also build an end-to-end live free-viewpoint system with a multi-user oriented streaming strategy. 
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/VCIP22-KaiZhou.png" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a href="https://ieeexplore.ieee.org/abstract/document/10008839">
                                        <papertitle>RGBD-based Real-time Volumetric Reconstruction System: Architecture Design and Implementation</papertitle>
                                    </a>
                                    <br>
                                    <a>Kai Zhou</a>,
                                    <a>Shuai Guo</a>,
                                    <u><strong>Jingchuan Hu</strong></u>,
                                    <a>Jionghao Wang</a>,
                                    <a>Qiuwen Wang</a>,
                                    <a href="https://medialab.sjtu.edu.cn/author/li-song/">Li Song</a>

                                    <br>
                                    <em>VCIP '22</em>
                                    <br>
                                    <p></p>
                                    <p>
                                        In this paper, a low-cost, real-time system: LiveRecon3D, is presented, with multiple RGB-D cameras connected to one single computer. The goal of the system is to provide an interactive frame rate for 3D content capture and rendering at a reduced cost.
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/R100Dataset.png" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a href="https://dl.acm.org/doi/abs/10.1145/3524273.3532897">
                                        <papertitle>A New Free Viewpoint Video Dataset and DIBR Benchmark</papertitle>
                                    </a>
                                    <br>
                                    <a>Shuai Guo</a>,
                                    <a>Kai Zhou</a>,
                                    <u><strong>Jingchuan Hu</strong></u>,
                                    <a>Jionghao Wang</a>,
                                    <a>Jun Xu</a>,
                                    <a href="https://medialab.sjtu.edu.cn/author/li-song/">Li Song</a>

                                    <br>
                                    <em>MMSys '22</em>
                                    <br>
                                    <p></p>
                                    <p>
                                        In this paper, we present a new dynamic RGB-D video dataset with up to 12 views. Our dataset consists of 13 groups of dynamic video sequences, taken in the same scene.
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/IBC21-KaiZhou.png" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a href="https://www.ibc.org/download?ac=18719">
                                        <papertitle>Real-time 3D Reconstruction Of Dynamic Scenes Wth Multiple Kinect V2 Sensors</papertitle>
                                    </a>
                                    <br>
                                    <a>Kai Zhou</a>,
                                    <a href="https://medialab.sjtu.edu.cn/author/li-song/">Li Song</a>,
                                    <u><strong>Jingchuan Hu</strong></u>,
                                    <a>Shuai Guo</a>,
                                    <a>Yu Dong</a>
                                    <br>
                                    <em>IBC '21</em>
                                    <br>
                                    <p></p>
                                    <p>
                                        In this paper, an open-solution, low-latency, real-time 3D reconstruction system is presented. The proposed system runs in a simple architecture where multiple Kinect v2 sensors are connected to a single computer.
                                        Experimental results are presented to verify the system's effectiveness concerning the 3D reconstruction visual quality and real-time performance.
                                </td>
                            </tr>


                        </tbody>
                    </table>

                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Projects</heading>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table style="width:100%;border:0;border-collapse:collapse;border-spacing:0;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <p>
                                Below are some of my recent projects. Some older projects of mine could be found on my <a href="https://github.com/Eric-chuan">Github</a>.
                            </p>


                            <!-- <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/depthRefine1.png" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a>
                                        <papertitle>Image-Guided Kinect Depth Refinement</papertitle>
                                    </a>
                                    <br>
                                    <p>
                                        We used RGB image, depth image
                                    </p>
                                </td>
                            </tr> -->
                            <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/AnimatedHumanRecon.gif" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a>
                                        <papertitle>Animated Human Reconstruction</papertitle>
                                    </a>
                                    <br>
                                    <p>
                                        We reconstructed and rendered animated human characters by neural rendering, using SMPL as a priori. 
                                        Specifically, we decoupled the process into geometric and texture reconstruction. 
                                        We implicitly represented the geometry of the human body using the signed distance function (SDF), while we learned fine textures through appearance blending.
                                        The animated human characters we finally reconstructed achieved good results in both geometry and texture.
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/BulletTimeVideo.gif" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a>
                                        <papertitle>Bullet Time Video</papertitle>
                                    </a>
                                    <br>
                                    <p>
                                        We Shoot multi-view videos in real time with a sparsely arranged multi-view camera system. 
                                        The captured highlights are converted into bullet time video in real time by a free view synthesis algorithm. 
                                        Bullet time video allows the audience to have the same immersive experience as in the movie <a href="https://www.youtube.com/watch?v=FOitGa117_s">"The Matrix"</a>.
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/DIBRlow.gif" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a>
                                        <papertitle>Depth Image Based Rendering</papertitle>
                                    </a>
                                    <br>
                                    <p>
                                        We used a rather traditional Depth-Image Based Rendering algorithm, which performs interpolation by warping neighboring view RGB values to novel view based on depth values, and then blend them together. The system is optimized and can run in real-time.
                                    </p>
                                </td>
                            </tr>


                            <!-- <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/MVS.png" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a>
                                        <papertitle>Learning-based Multiview Stereo</papertitle>
                                    </a>
                                    <br>
                                    <p>
                                        We mimick the traditional Patchmatch-based algorithm for dense multi-view stereo with a deep neural network, and perform dense depth estimation for multi-view images.
                                    </p>
                                </td>
                            </tr> -->

                        </tbody>

                    </table>

                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td>
                                    <heading>Education</heading>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table width="100%" align="center" border="0" cellpadding="20">
                        <tbody>
                            <!--<tr>
							<td style="padding:20px;width:25%;vertical-align:middle"><img width="100" src="./images/Cornell.png"></td>
							<td width="75%" valign="center">
							<p> Cornell University, Ph.D. in Computer Science, 2023 - 2028 (expected) </p>
							</td>
								</tr>-->
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle"><img width="100" src="./images/SJTU-Badge.png"></td>
                                <td width="75%" valign="center">
                                    <p>
                                        MS. in Information Engineering, EE Department <span style="display:inline-block;width:60px">&nbsp;</span> 2020.09 - 2023.03
                                    </p>
                                    <a>
                                        <papertitle>Shanghai Jiao Tong University, China</papertitle>
                                    </a>
                                </td>
                            </tr>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle"><img width="100" src="./images/SJTU-Badge.png"></td>
                                <td width="75%" valign="center">
                                    <p>
                                        B.Eng. in Information Engineering, EE Department <span style="display:inline-block;width:45px">&nbsp;</span> 2016.09 - 2020.06
                                    </p>
                                    <a>
                                        <papertitle>Shanghai Jiao Tong University, China</papertitle>
                                    </a>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td>
                                    <heading>Experiences</heading>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table width="100%" align="center" border="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle"><img width="150" src="./images/Alibaba.png"></td>
                                <td width="75%" valign="center">
                                    <p>
                                        Applied Algorithm Engineering <span style="display:inline-block;width:161px">&nbsp;</span> 2023.03 - Present
                                    </p>
                                    <a>
                                        <papertitle>Tao Technology Department, Alibaba, China</papertitle>
                                    </a>
                    
                                    <!-- <p>
                                        I developed a RGB-D fusion pipeline, including a depth processing algorithm, which was published as an academic paper in DTTC (Intel's Design and Test Technology Conference).
                                    </p> -->
                                </td>
                            </tr>
                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle"><img width="150" src="./images/ByteDance.png"></td>
                                <td width="75%" valign="center">
                                    <p>
                                        3D Vision Algorithm Engineering Intern <span style="display:inline-block;width:107px">&nbsp;</span> 2022.06 - 2023.02
                                    </p>
                                    <a>
                                        <papertitle>Multimedia Lab, ByteDance, China</papertitle>
                                    </a>
                    
                                    <!-- <p>
                                        I developed a RGB-D fusion pipeline, including a depth processing algorithm, which was published as an academic paper in DTTC (Intel's Design and Test Technology Conference).
                                    </p> -->
                                </td>
                            </tr>

                        </tbody>
                    </table>


                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td>
                                    <heading>Miscellaneous</heading>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table width="100%" align="center" border="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td width="100%" valign="center">
                                    <p>
                                        I have a passion for fitness and enjoy challenging myself with various workout routines. My focus is primarily on weight training, specifically barbell exercises such as bench press, squats, and deadlifts.
                                        My current personal records include a 90kg bench press, a 120kg squat, and a 120kg deadlift.
                                        Fitness is not just a hobby for me, it is a way of life and I am excited to see what new challenges and accomplishments lie ahead.
                                        I am excited to continue this journey of growth and self-improvement, both in and out of the gym.
                                        <!-- I also wrote several movie critics on movies such as <a href="https://www.imdb.com/title/tt0056291/"><em>Nóż w wodzie</em></a>, <a href="https://www.imdb.com/title/tt0087884/"><em>Paris, Texas</em></a> and <a href="https://www.imdb.com/title/tt0102943/"><em>Slackers</em></a>. -->
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <!--<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td>
                                    <heading>Friends</heading>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table width="100%" align="center" border="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td width="100%" valign="center">
                                    <p>New York University: <a href="https://xichenpan.com/">Xichen Pan</a></p>
                                    <p>UESTC: <a href="https://kunkun0w0.github.io/">Zekun Li</a></p>



                                    <p></p>
                                    <details close="">
                                        <summary>You can also find me on different social media.</summary>
                                        <p>My Wechat is denghilbert and QQ is 971431670</p>
                                    </details>
                                    <p></p>
                                </td>
                            </tr>
                        </tbody>
                    </table>-->


                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:0px">
                                    <br>
                                    <p style="text-align:right;font-size:small;">
                                        Website template borrowed from Jon Barron's personal page <a href="https://jonbarron.info/">Here</a>
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                </td>
            </tr>
        </tbody>
    </table>



</body>

</html>